# -*- coding: utf-8 -*-
"""20230101to20230410_H1_KD_golden_death_cross_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ePr2xReYhb8rMFuP1fsNfUxwZaqr87VT
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.utils import np_utils
from sklearn import preprocessing

df = pd.read_excel("20230101to20230410_H1.xlsx") #  資料時間:20190601~20210601

# df["Date"] = pd.to_datetime(df["TimeCurrent"])
df

# 抓取全部的資料，且只要Open~day
# 若是要抓取特定資料(3筆)，那就:3
x = df.loc[:, 'fastline':'golden_death_cross']
x

#用pandas轉成numpy數組
x = x.values

y = df.loc[:, 'winorlose_bool']

y

from imblearn.over_sampling import SMOTE
# 定义SMOTE模型，random_state相当于随机数种子的作用
# 平衡樣本數
smo = SMOTE(random_state=42)
x = x.astype('float64')
x, y = smo.fit_resample(x, y)

from sklearn import preprocessing

# One-Hot編碼(順便轉成np)
encoder = preprocessing.LabelEncoder()
y = encoder.fit_transform(y)
y = np_utils.to_categorical(y)

y

X_train = x
Y_train = y

print(x.shape)

import numpy as np
"""数据归一化（最大最小方法）"""
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
scaler.fit(X_train)   #训练

# 歸一化之前
print(X_train[0])

X_train = scaler.transform(X_train)     #此时输出的X_train就是数组了 

# 歸一化之後
print(X_train[0])

from keras.models import Sequential
from keras.layers import Dense
import tensorflow as tf

"""顺序模型：类似于搭积木一样一层、一层放上去"""
# 用Sequential建立模型
model = tf.keras.Sequential()


"""添加层:其实就是 wx+b"""
model.add(tf.keras.layers.Dense(units=50, activation='relu', input_dim=3))
# model.add(tf.keras.layers.Dropout(0.2))
# model.add(tf.keras.layers.Dense(units=150, activation='relu'))
# model.add(tf.keras.layers.Dropout(0.2))
# model.add(tf.keras.layers.Dense(units=75, activation='relu'))
# model.add(tf.keras.layers.Dropout(0.2))
# model.add(tf.keras.layers.Dense(units=50, activation='relu'))
model.add(tf.keras.layers.Dense(units=25, activation='relu'))
model.add(tf.keras.layers.Dense(units=10, activation='relu'))
model.add(tf.keras.layers.Dense(units=2, activation='softmax'))




#編譯模型
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])


# 顯示模型
tf.keras.utils.plot_model(model,show_shapes=True)

#===================================================================

"""编译，配置"""
# model每層定義好後需要經過compile
# optimizer最佳化工具為adam
# 方法為keras.losses.mean_squared_error

model.compile(optimizer= 'adam',
               loss=['categorical_crossentropy'],
               metrics=['accuracy']
                  )
# 多分類loss函數:categorical_crossentropy
# 二分類loss函數:binary_crossentropy

"""训练数据"""
# 早停
callback = EarlyStopping(monitor="val_accuracy", patience=10, verbose=1, mode="max")
# val_accuracy

history = model.fit(X_train, Y_train,validation_split=0.33,batch_size=200,epochs = 2000) #, callbacks=[callback]

# 評估模型
loss, accuracy = model.evaluate(X_train, Y_train)
print("訓練資料集的準確度 = {:.2f}".format(accuracy))

# 顯示訓練和驗證損失圖表
import matplotlib.pyplot as plt

loss = history.history["loss"]
epochs = range(1, len(loss)+1)
val_loss = history.history["val_loss"]
plt.plot(epochs, loss, "bo", label="Training Loss")
plt.plot(epochs, val_loss, "r", label="Validation Loss")
plt.title("Training and Validation Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()
# 顯示訓練和驗證準確度
acc = history.history["accuracy"]
epochs = range(1, len(acc)+1)
val_acc = history.history["val_accuracy"]
plt.plot(epochs, acc, "b-", label="Training Acc")
plt.plot(epochs, val_acc, "r--", label="Validation Acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

# 绘制训练 & 验证的准确率值
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()



# 绘制训练 & 验证的损失值
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()